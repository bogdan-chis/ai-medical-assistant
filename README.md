# Dr. Dialogue ğŸ¤–ğŸ¥

> **A medicalâ€domain conversational assistant** powered by retrievalâ€augmented generation (RAG) over a curated doctorâ€“patient dialogue dataset, with answer evaluation via a secondary LLM. ğŸ’¬ğŸ“š

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)  
2. [Features](#features)  
3. [Architecture](#architecture)  
4. [Repository Structure](#repository-structure)  
5. [Installation & Setup](#installation--setup)  
6. [Configuration](#configuration)  
7. [Data Ingestion & Embedding](#data-ingestion--embedding)  
8. [Running the API Server](#running-the-api-server)  
9. [Frontend (React) Setup](#frontend-react-setup)  
10. [Example Usage](#example-usage)  
11. [Evaluation Pipeline (DeepEval)](#evaluation-pipeline-deepeval)  
12. [Environment Variables](#environment-variables)  
13. [Contributing](#contributing)  
14. [License](#license)  
15. [Short Project Description](#short-project-description)  

---

## ğŸ§ Project Overview

**Dr. Dialogue** began as a generic researchâ€assistant framework but has been specialized into a **medical assistant**. It leverages a locally hosted LLM (via LM Studio) and a doctorâ€“patient conversation dataset to answer user (patient) queries with contextually relevant, upâ€toâ€date medical information. All answers are then run through a secondary â€œDeepEvalâ€ LLM to ensure consistency, accuracy, and safety before returning to the user. ğŸ”’âœ…

---

## âœ¨ Features

- **ğŸ” Retrievalâ€Augmented Generation (RAG):**  
  - Ingests and preprocesses raw doctorâ€“patient transcripts.  
  - Splits and embeds each chunk with a local embeddings service.  
  - Stores embeddings in ChromaDB for fast nearestâ€neighbor lookups.  
  - Retrieves the most relevant snippets at query time and supplies them as context to the LLM.

- **ğŸ¥ Local LLM Hosting:**  
  - **Primary LLM** (e.g., a fineâ€tuned medical model) runs on a local LM Studio instance.  
  - **Secondary LLM (DeepEval)** also hosted locally to evaluate clarity, quality, and safety of each generated response.

- **âš™ï¸ FastAPI Backend:**  
  - Exposes REST endpoints for ingestion, querying, and evaluation.  
  - Manages ingestion triggers, embedding calls, RAG orchestration, and evaluation pipelines.

- **ğŸ–¥ï¸ React Frontend:**  
  - Provides a simple chat interface for endâ€users (patients).  
  - Sends user queries over HTTP, receives and displays filtered, LLMâ€generated medical guidance.

- **ğŸ›¡ï¸ Safety & Guardrails:**  
  - Integrates Perspective API to filter responses for harmful or disallowed content.  
  - Maintains custom promptâ€engineering templates and guardrails for medical disclaimers.

---

## ğŸ—ï¸ Architecture

```text
+-------------------------------------------------------------+
|                         Frontend Layer                      |
|  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  |
|  | React UI  <â”€â”€â”€ HTTP: Query/Response â”€â”€  HTTP Wrappers |  |
|  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  |
|                              â”‚                              |
|                              â–¼                              |
|                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   |
|                     â”‚  API Server       â”‚                   |
|                     â”‚  (FastAPI)         â”‚â—€â”€â”              |
|                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                |
+-------------------------------------------------------------+
          â”‚            â–²                      â”‚
          â”‚            â”‚                      â”‚
          â”‚         Trigger                   â”‚
          â”‚         Ingestion                 â”‚
          â–¼            â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚       Ingestion & Preprocessing   â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚
â”‚  â”‚Dataset      â”‚â”€â”€â–¶ â”‚Document   â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â”‚Loader       â”‚    â”‚Splitter   â”‚â—€â”€â”˜
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚         â”‚                  â”‚
â”‚         â–¼                  â–¼
â”‚   Postprocessing        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚              â”‚ Embeddings   â”‚
â”‚         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Service      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
       Query Embeddings          â”‚
                                â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚Vector Store   â”‚
                          â”‚Interface      â”‚â”€â”€â”€â”
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                                  â”‚           â”‚
                                  â–¼           â”‚
                           Retrieve Context    â”‚
                                  â”‚           â”‚
                                  â–¼           â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
                             â”‚   RAG     â”‚â”€â”€â”€â”€â”€â”˜
                             â”‚ Service   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ LLM      â”‚             â”‚ DeepEval   â”‚
                â”‚ Client   â”‚             â”‚ Client     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚                         â”‚
                     â”‚                         â”‚
             (Response from LLM)        (Evaluation Score)
                     â”‚                         â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â–¼
                            Final Response
